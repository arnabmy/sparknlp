{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_on_Apache_Spark.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPBwdCsBCnCLKxsd8ZUWWdw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnabmy/sparknlp/blob/main/NLP_on_Apache_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3UG0eKCqoqW",
        "outputId": "cb8033ea-51a0-4a83-c3e3-f4f52714205f"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.4\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.5.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_282\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_282-8u282-b08-0ubuntu1~18.04-b08)\n",
            "OpenJDK 64-Bit Server VM (build 25.282-b08, mixed mode)\n",
            "Collecting pyspark==2.4.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 68kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 42.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130389 sha256=836d4a7f5d53b27ae265554f361d1ad0434c6deb1c3e3ea3100e8f1ed1c21f09\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n",
            "Collecting spark-nlp==2.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/b4/db653f8080a446de8ce981b262d85c85c61de7e920930726da0d1c6b4c65/spark_nlp-2.5.1-py2.py3-none-any.whl (121kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 4.4MB/s \n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-_Cwe6oqsc4"
      },
      "source": [
        "! mkdir -p data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFgNu0OLqv9P",
        "outputId": "bca5d942-6fb8-47c9-921c-96f53e855b06"
      },
      "source": [
        "! wget https://archive.ics.uci.edu/ml/machine-learning-databases/20newsgroups-mld/mini_newsgroups.tar.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-16 12:33:15--  https://archive.ics.uci.edu/ml/machine-learning-databases/20newsgroups-mld/mini_newsgroups.tar.gz\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1860687 (1.8M) [application/x-httpd-php]\n",
            "Saving to: ‘mini_newsgroups.tar.gz’\n",
            "\n",
            "mini_newsgroups.tar 100%[===================>]   1.77M  3.96MB/s    in 0.4s    \n",
            "\n",
            "2021-04-16 12:33:16 (3.96 MB/s) - ‘mini_newsgroups.tar.gz’ saved [1860687/1860687]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4vb-OIaqzSo"
      },
      "source": [
        "! tar xzf mini_newsgroups.tar.gz -C ./data/"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjGDrtp8q24E",
        "outputId": "e1b91b08-4c27-4b7b-f446-65c1a4bd0dfa"
      },
      "source": [
        "! wget https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-16 12:33:17--  https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4551 (4.4K) [application/x-httpd-php]\n",
            "Saving to: ‘iris.data’\n",
            "\n",
            "iris.data           100%[===================>]   4.44K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-16 12:33:17 (144 MB/s) - ‘iris.data’ saved [4551/4551]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12k5GB5Wq5R_"
      },
      "source": [
        "! mv iris.data ./data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xhlic2oaq-Ki",
        "outputId": "2d10a24c-cad9-4718-966d-c6c0f871eda8"
      },
      "source": [
        "! wget https://github.com/alexander-n-thomas/spark-nlp-book-prod/raw/master/en_lemmas.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-16 12:33:35--  https://github.com/alexander-n-thomas/spark-nlp-book-prod/raw/master/en_lemmas.txt\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/alexander-n-thomas/spark-nlp-book/raw/master/en_lemmas.txt [following]\n",
            "--2021-04-16 12:33:35--  https://github.com/alexander-n-thomas/spark-nlp-book/raw/master/en_lemmas.txt\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/alexander-n-thomas/spark-nlp-book/master/en_lemmas.txt [following]\n",
            "--2021-04-16 12:33:36--  https://raw.githubusercontent.com/alexander-n-thomas/spark-nlp-book/master/en_lemmas.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 646019 (631K) [text/plain]\n",
            "Saving to: ‘en_lemmas.txt’\n",
            "\n",
            "en_lemmas.txt       100%[===================>] 630.88K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-04-16 12:33:36 (11.9 MB/s) - ‘en_lemmas.txt’ saved [646019/646019]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NZUxA3orBsr"
      },
      "source": [
        "from operator import concat, itemgetter, methodcaller\n",
        "import os\n",
        "from time import sleep\n",
        "\n",
        "import pyspark\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as fun\n",
        "from pyspark.sql.types import *"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IQKJOLqrOIr"
      },
      "source": [
        "packages = ','.join([\n",
        "    \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.4.5\",\n",
        "])\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"spark-nlp-book-p1c3\") \\\n",
        "    .config(\"spark.jars.packages\", packages)\\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "SF639pccrQ-S",
        "outputId": "db7d44ad-7862-4c1d-f727-3bc38cf53d72"
      },
      "source": [
        "spark"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://a92faa049f5f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.4.4</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>spark-nlp-book-p1c3</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fdf5561b210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ_kKMTsrXIw"
      },
      "source": [
        "def has_moon(text):\n",
        "    if 'moon' in text:\n",
        "        sleep(1)\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZi3AAPGrqbQ"
      },
      "source": [
        "# RDD containing filepath-text pairs\n",
        "path = os.path.join('data', 'mini_newsgroups', 'sci.space')\n",
        "text_pairs = spark.sparkContext.wholeTextFiles(path)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjyhFROvrsJ-",
        "outputId": "d5fc7729-8189-405a-b210-cd037a4eea42"
      },
      "source": [
        "text_pairs"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "org.apache.spark.api.java.JavaPairRDD@6af55935"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44m1HCKmr62k"
      },
      "source": [
        "texts = text_pairs.map(itemgetter(1))\n",
        "lower_cased = texts.map(methodcaller('lower'))\n",
        "moon_texts = texts.filter(has_moon).persist()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG4xX1icsF7t",
        "outputId": "a3548dcb-db69-4895-8e93-f7918fd7c892"
      },
      "source": [
        "print('This appears quickly because the previous operations are '\n",
        "      'all lazy')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This appears quickly because the previous operations are all lazy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9yHWo5RsVdJ",
        "outputId": "4a197ab7-f8cf-4a08-ec08-e91bdd563769"
      },
      "source": [
        "print(moon_texts.count())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZta3Q_Psbnn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}